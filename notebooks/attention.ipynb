{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BytePairTokenizer:\n",
    "    def __init__(self, data_path:str=None) -> None:\n",
    "        \"\"\"\n",
    "        BytePairTokenizer object\n",
    "        \"\"\"\n",
    "        if data_path:\n",
    "            self.load_model(data_path)\n",
    "            return\n",
    "        \n",
    "        self.special_tokens:Dict[str, int] = {\n",
    "            '<BOT>': 0,  # Beginning of Text\n",
    "            '<EOT>': 1,   # End of Text\n",
    "            '</w>': 2     # end of word\n",
    "        }\n",
    "        self.inv_special_tokens:Dict[int, str] = {i: t for t, i in self.special_tokens.items()}\n",
    "\n",
    "        self.token_map: Dict[str, int] = self.special_tokens.copy()\n",
    "        self.inv_map: Dict[int, str] = self.inv_special_tokens.copy()\n",
    "        self.bpe_codes: Dict[Tuple[str, str], int] = {}\n",
    "    \n",
    "    def train(self, corpus: List[str], num_merges: int, verbose:bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Train the Byte Pair Tokenizer to process sentences.\n",
    "        \"\"\"\n",
    "        # Build the vocabulary: map token sequences to their frequencies\n",
    "        vocab = {}\n",
    "        if verbose:\n",
    "            print(\"Building vocabulary...\")\n",
    "        for sentence in tqdm(corpus):\n",
    "            # Split sentence into words with leading whitespace preserved\n",
    "            words = re.findall(r'\\s*\\S+|\\s+', sentence)\n",
    "            for word in words:\n",
    "                # Skip special tokens\n",
    "                if word in self.special_tokens.keys():\n",
    "                    continue\n",
    "                chars = list(word) + ['</w>']\n",
    "                word_tuple = tuple(chars)\n",
    "                vocab[word_tuple] = vocab.get(word_tuple, 0) + 1\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Vocabulary built.\\nTraining BPE...\")\n",
    "        token_id = len(self.token_map)  # Starting token ID\n",
    "        symbols = set()\n",
    "        for word_tuple in vocab.keys():\n",
    "            symbols.update(word_tuple)\n",
    "        for symbol in symbols:\n",
    "            if symbol not in self.token_map:\n",
    "                self.token_map[symbol] = token_id\n",
    "                token_id += 1\n",
    "        self.inv_map = {i: t for t, i in self.token_map.items()}\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Token map built.\\nMerging tokens...\")\n",
    "        # Perform BPE merges\n",
    "        for i in tqdm(range(num_merges)):\n",
    "            pairs = self._get_pair_counts(vocab)\n",
    "            if not pairs:\n",
    "                break\n",
    "            best_pair = max(pairs, key=pairs.get)\n",
    "            vocab = self._merge_vocab(best_pair, vocab)\n",
    "            self.bpe_codes[best_pair] = i # Record the BPE merge rule\n",
    "            new_symbol = ''.join(best_pair)\n",
    "            if new_symbol not in self.token_map:\n",
    "                self.token_map[new_symbol] = token_id\n",
    "                token_id += 1\n",
    "                self.inv_map[self.token_map[new_symbol]] = new_symbol\n",
    "    \n",
    "    def _get_pair_counts(self, vocab: Dict[Tuple[str], int]) -> Dict[Tuple[str, str], int]:\n",
    "        \"\"\"\n",
    "        Get counts of symbol pairs in the vocabulary\n",
    "        \"\"\"\n",
    "        pairs = {}\n",
    "        for word, freq in vocab.items():\n",
    "            symbols = word\n",
    "            for i in range(len(symbols) - 1):\n",
    "                pair = (symbols[i], symbols[i + 1])\n",
    "                pairs[pair] = pairs.get(pair, 0) + freq\n",
    "        return pairs\n",
    "    \n",
    "    def _merge_vocab_single(self, pair: Tuple[str, str], vocab: Dict[Tuple[str], int]) -> Dict[Tuple[str], int]:\n",
    "        \"\"\"\n",
    "        Merge all occurrences of the given pair in the vocabulary\n",
    "        \"\"\"\n",
    "        new_vocab = {}\n",
    "        bigram = ''.join(pair)\n",
    "        for word, freq in vocab.items():\n",
    "            w = []\n",
    "            i = 0\n",
    "            while i < len(word):\n",
    "                # Merge the pair if found\n",
    "                if i < len(word) - 1 and word[i] == pair[0] and word[i + 1] == pair[1]:\n",
    "                    w.append(bigram)\n",
    "                    i += 2\n",
    "                else:\n",
    "                    w.append(word[i])\n",
    "                    i += 1\n",
    "            new_vocab[tuple(w)] = freq\n",
    "        return new_vocab\n",
    "\n",
    "    @staticmethod\n",
    "    def _process_word(args):\n",
    "        pair, word_freq = args\n",
    "        word, freq = word_freq\n",
    "        bigram = ''.join(pair)\n",
    "        w = []\n",
    "        i = 0\n",
    "        while i < len(word):\n",
    "            if i < len(word) - 1 and word[i] == pair[0] and word[i + 1] == pair[1]:\n",
    "                w.append(bigram)\n",
    "                i += 2\n",
    "            else:\n",
    "                w.append(word[i])\n",
    "                i += 1\n",
    "        return tuple(w), freq\n",
    "    \n",
    "    def _merge_vocab(self, pair: Tuple[str, str], vocab: Dict[Tuple[str], int]) -> Dict[Tuple[str], int]:\n",
    "        \"\"\"\n",
    "        Parallel merge of all occurrences of the given pair in the vocabulary using multiprocessing.\n",
    "        \"\"\"\n",
    "        with Pool() as pool:\n",
    "            results = pool.map(self._process_word, [(pair, word_freq) for word_freq in vocab.items()])\n",
    "\n",
    "        new_vocab = {word: freq for word, freq in results}\n",
    "        return new_vocab\n",
    "    \n",
    "    def _get_pairs(self, word: List[str]) -> set:\n",
    "        \"\"\"\n",
    "        Return a set of symbol pairs in a word\n",
    "        \"\"\"\n",
    "        pairs = set()\n",
    "        for i in range(len(word) - 1):\n",
    "            pairs.add((word[i], word[i + 1]))\n",
    "        return pairs\n",
    "    \n",
    "    def _apply_bpe(self, word: List[str]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Apply BPE to a list of symbols (a word)\n",
    "        \"\"\"\n",
    "        word = word.copy()\n",
    "        pairs = self._get_pairs(word)\n",
    "        while True:\n",
    "            if not pairs:\n",
    "                break\n",
    "            # Find the highest priority pair to merge\n",
    "            min_pair = None\n",
    "            min_rank = float('inf')\n",
    "            for pair in pairs:\n",
    "                if pair in self.bpe_codes:\n",
    "                    rank = self.bpe_codes[pair]\n",
    "                    if rank < min_rank:\n",
    "                        min_rank = rank\n",
    "                        min_pair = pair\n",
    "            if min_pair is None:\n",
    "                break\n",
    "            # Merge the best pair\n",
    "            new_symbol = ''.join(min_pair)\n",
    "            i = 0\n",
    "            while i < len(word) - 1:\n",
    "                if word[i] == min_pair[0] and word[i + 1] == min_pair[1]:\n",
    "                    word[i:i + 2] = [new_symbol]\n",
    "                    i = max(i - 1, 0)  # Restart from the previous position after a merge\n",
    "                else:\n",
    "                    i += 1\n",
    "            pairs = self._get_pairs(word)\n",
    "        return word\n",
    "    \n",
    "    def split_text(self, text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Split text into BPE tokens with leading whitespace preserved\n",
    "        \"\"\"\n",
    "        tokens = []\n",
    "        words = re.findall(r'\\s*\\S+|\\s+', text)\n",
    "        for word in words:\n",
    "            chars = list(word) + ['</w>']\n",
    "            bpe_word = self._apply_bpe(chars)\n",
    "            tokens.extend(bpe_word)\n",
    "        return tokens\n",
    "    \n",
    "    def encode(self, data: str) -> List[int]:\n",
    "        \"\"\"\n",
    "        Encode text data into a list of token IDs\n",
    "        \"\"\"\n",
    "        str_list = self.split_text(data)\n",
    "        token_list = [self.token_map[tok] for tok in str_list]\n",
    "        return token_list\n",
    "    \n",
    "    def decode(self, data: List[int]) -> str:\n",
    "        \"\"\"\n",
    "        Decode a list of token IDs back into text\n",
    "        \"\"\"\n",
    "        tokens = [self.inv_map[i] for i in data]\n",
    "        text = ''\n",
    "        for token in tokens:\n",
    "            if token != '</w>':\n",
    "                text += token.replace('</w>', '')\n",
    "        return text\n",
    "\n",
    "    def save_model(self, target_path:str) -> None:\n",
    "        \"\"\"\n",
    "        Save the model to a file as json file\n",
    "        the json will look like\n",
    "        {\n",
    "            token_map : {...},\n",
    "            bpe_codes : {...}\n",
    "        }\n",
    "        The special tokens are not necessary for simple encoding/decoding\n",
    "        hence it is omitted from the model\n",
    "        \"\"\"\n",
    "        with open(target_path, 'w', encoding=\"UTF-8\") as f:\n",
    "            json.dump({\n",
    "                'token_map': self.token_map,\n",
    "                'bpe_codes': {json.dumps(list(k)): v for k, v in self.bpe_codes.items()}\n",
    "            }, f,\n",
    "             indent=4,\n",
    "              ensure_ascii=False)\n",
    "    \n",
    "    def load_model(self, model_path:str, encoding=\"UTF-8\") -> None:\n",
    "        \"\"\"\n",
    "        Load the model from a json file\n",
    "        JSON doesn't allow tuple object as key\n",
    "        hence the tuple keys are converted to string before saving\n",
    "        and converted back to tuple when loading\n",
    "        \"\"\"\n",
    "        with open(model_path, 'r') as f:\n",
    "            model = json.load(f)\n",
    "        self.token_map = model['token_map']\n",
    "        self.inv_map = {i: t for t, i in self.token_map.items()}\n",
    "        self.bpe_codes = {tuple(json.loads(k)): v for k, v in model['bpe_codes'].items()}\n",
    "\n",
    "def load_tokenizer(path:str = None) -> BytePairTokenizer:\n",
    "    \"\"\"\n",
    "    Load the BytePairTokenizer model from the model folder\n",
    "    \"\"\"\n",
    "    if path is None:\n",
    "        model_path:str = os.path.join(os.getcwd(), 'model', 'tokenizer.json')\n",
    "    else:\n",
    "        model_path:str = path\n",
    "    tokenizer = BytePairTokenizer(model_path)\n",
    "    # tokenizer.load_model(model_path)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [1777, 4313, 2964, 4313, 3279, 2804, 3914, 3066, 4889, 2871, 10120, 2896, 3070, 3399, 3182, 3474, 5091, 2765, 2963, 3001, 3580, 2796, 3181, 10557, 3698, 3496, 2854, 3874, 4855, 2837, 2871, 7153, 5263, 2772, 5468, 2893, 7311, 3175, 2764, 3175, 2764, 10580]\n",
      "Decoded: Sean Bean has a hard time leaving his role as Eddard Stark . He vows to get revenge against those that assisted in his execution , starting with George R. R. Martin\n"
     ]
    }
   ],
   "source": [
    "# Test the BytePairTokenizer\n",
    "tokenizer = load_tokenizer()\n",
    "text = 'Sean Bean has a hard time leaving his role as Eddard Stark . He vows to get revenge against those that assisted in his execution , starting with George R. R. Martin'\n",
    "encoded = tokenizer.encode(text)\n",
    "print(f\"Encoded: {encoded}\")\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(f\"Decoded: {decoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import tensor, Tensor\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.set_default_device(device)\n",
    "    print(f\"Using {torch.cuda.get_device_name()}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    torch.set_default_device(device)\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 10948\n"
     ]
    }
   ],
   "source": [
    "vocab_size:int = len(tokenizer.token_map)\n",
    "embedding_dim:int = 1536\n",
    "\n",
    "print(f\"Vocab size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinear:\n",
    "    def __init__(self, input_size: int, output_size: int) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_size (int): 입력 피처의 크기\n",
    "            output_size (int): 출력 피처의 크기\n",
    "        \"\"\"\n",
    "        self.input_size: int = input_size\n",
    "        self.output_size: int = output_size\n",
    "        self.weights: Tensor = torch.rand(input_size, output_size) # 가중치 랜덤 초기화\n",
    "\n",
    "    def forward(self, inputs: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        입력에 가중치를 단순 행렬곱하여 출력\n",
    "\n",
    "        Args:\n",
    "            inputs (Tensor): 입력 텐서 [batch_size, input_size]\n",
    "\n",
    "        Returns:\n",
    "            Tensor: 출력 텐서 [batch_size, output_size]\n",
    "        \"\"\"\n",
    "        self.inputs: Tensor = inputs\n",
    "        self.output: Tensor = torch.mm(inputs, self.weights) # 단순 행렬곱\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, grad_output: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        손실 함수 그래디언트 이전 층으로 전달 및 가중치 그래디언트 계산\n",
    "\n",
    "        Args:\n",
    "            grad_output (Tensor): 상위 레이어로부터 전달된 그래디언트 [batch_size, output_size]\n",
    "\n",
    "        Returns:\n",
    "            Tensor: 하위 레이어로 전달할 그래디언트 [batch_size, input_size]\n",
    "        \"\"\"\n",
    "\n",
    "        grad_input: Tensor = torch.mm(grad_output, self.weights.t()) # 단순 행렬곱\n",
    "        self.grad_weights: Tensor = torch.mm(self.inputs.t(), grad_output)\n",
    "        return grad_input\n",
    "\n",
    "class Embedding:\n",
    "    def __init__(self, input_dim: int, output_dim: int) -> None:\n",
    "        \"\"\"\n",
    "        Custom Embedding 레이어 초기화\n",
    "\n",
    "        Args:\n",
    "            input_dim (int): 임베딩할 인덱스의 개수 (예: 단어 집합의 크기)\n",
    "            output_dim (int): 임베딩 벡터의 차원\n",
    "        \"\"\"\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        # 임베딩 매트릭스를 학습 가능한 파라미터로 초기화\n",
    "        self.weights: Tensor = torch.randn(input_dim, output_dim) * 0.01\n",
    "        self.grad_weights: Tensor = torch.zeros_like(self.weights)\n",
    "\n",
    "    def forward(self, input_indices: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        순전파 과정\n",
    "\n",
    "        Args:\n",
    "            input_indices (Tensor): 정수 인덱스 텐서 (예: [batch_size, sequence_length])\n",
    "\n",
    "        Returns:\n",
    "            Tensor: 임베딩된 벡터 텐서 (예: [batch_size, sequence_length, output_dim])\n",
    "        \"\"\"\n",
    "        self.input_indices = input_indices\n",
    "        # 인덱스를 사용하여 임베딩 벡터 선택\n",
    "        self.output = self.weights[input_indices]\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, grad_output: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        역전파 과정\n",
    "\n",
    "        Args:\n",
    "            grad_output (Tensor): 상위 레이어로부터 전달된 그래디언트 (예: [batch_size, sequence_length, output_dim])\n",
    "\n",
    "        Returns:\n",
    "            Tensor: 하위 레이어로 전달할 그래디언트 (임베딩 레이어의 경우 없음)\n",
    "        \"\"\"\n",
    "        # grad_output의 형태: [batch_size, sequence_length, output_dim]\n",
    "        # 이를 [batch_size * sequence_length, output_dim]로 평탄화\n",
    "        grad_flat = grad_output.view(-1, self.output_dim)\n",
    "        # input_indices를 평탄화하여 [batch_size * sequence_length] 형태로 \n",
    "        input_flat = self.input_indices.view(-1)\n",
    "        \n",
    "        # 그래디언트를 초기화\n",
    "        self.grad_weights.zero_()\n",
    "        # 그래디언트 누적\n",
    "        self.grad_weights.index_add_(0, input_flat, grad_flat)\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"CustomEmbedding\"\n",
    "\n",
    "class PositionalEncoding:\n",
    "    def __init__(self, max_seq_len: int, embed_size: int):\n",
    "        \"\"\"\n",
    "        위치 인코딩 초기화\n",
    "\n",
    "        Args:\n",
    "            max_seq_len (int): 최대 시퀀스 길이\n",
    "            embed_size (int): 임베딩 차원\n",
    "        \"\"\"\n",
    "        self.embed_size = embed_size\n",
    "        self.pos_encoding = torch.zeros(max_seq_len, embed_size)\n",
    "\n",
    "        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_size, 2) * (-torch.log(torch.tensor(10000.0)) / embed_size))\n",
    "        self.pos_encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.pos_encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pos_encoding = self.pos_encoding.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        순전파 과정\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): 임베딩된 입력 텐서 [seq_length, embed_size]\n",
    "\n",
    "        Returns:\n",
    "            Tensor: 위치 인코딩이 추가된 텐서 [seq_length, embed_size]\n",
    "        \"\"\"\n",
    "        seq_length, embed_size = x.shape\n",
    "\n",
    "        # Ensure positional encoding matches input size\n",
    "        pos_encoding = self.pos_encoding[:, :seq_length, :]  # Slice for the current sequence length\n",
    "\n",
    "        return x + pos_encoding.to(x.device)  # Add positional encoding to the input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedding and positional encoding layers\n",
    "embedding = Embedding(vocab_size, embedding_dim)\n",
    "pos_encoding = PositionalEncoding(len(encoded), embedding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tokens: [1777, 4313, 2964, 4313, 3279, 2804, 3914, 3066, 4889, 2871, 10120, 2896, 3070, 3399, 3182, 3474, 5091, 2765, 2963, 3001, 3580, 2796, 3181, 10557, 3698, 3496, 2854, 3874, 4855, 2837, 2871, 7153, 5263, 2772, 5468, 2893, 7311, 3175, 2764, 3175, 2764, 10580]\n",
      "Embedded: torch.Size([42, 1536])\n",
      "Positional Encoding Applied: torch.Size([1, 42, 1536])\n"
     ]
    }
   ],
   "source": [
    "# Perform forward pass\n",
    "print(f\"Input Tokens: {encoded}\")\n",
    "embedded = embedding.forward(tensor(encoded))\n",
    "print(f\"Embedded: {embedded.shape}\")\n",
    "pos_encoded = pos_encoding.forward(embedded)\n",
    "print(f\"Positional Encoding Applied: {pos_encoded.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42, 1536])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_encoded = pos_encoded[0, :, :]\n",
    "pos_encoded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42, 1536])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_encoded.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: torch.Size([42, 1536])\n",
      "K: torch.Size([42, 1536])\n",
      "V: torch.Size([42, 1536])\n"
     ]
    }
   ],
   "source": [
    "W_q = SimpleLinear(embedding_dim, embedding_dim)    \n",
    "W_k = SimpleLinear(embedding_dim, embedding_dim)\n",
    "W_v = SimpleLinear(embedding_dim, embedding_dim)\n",
    "\n",
    "Q = W_q.forward(pos_encoded)\n",
    "K = W_k.forward(pos_encoded)\n",
    "V = W_v.forward(pos_encoded)\n",
    "\n",
    "print(f\"Q: {Q.shape}\")\n",
    "print(f\"K: {K.shape}\")\n",
    "print(f\"V: {V.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: torch.Size([42, 42])\n",
      "tensor([[2.2644e+08, 2.4381e+08, 2.4491e+08,  ..., 1.6132e+08, 1.6079e+08,\n",
      "         1.5981e+08],\n",
      "        [2.4381e+08, 2.6251e+08, 2.6369e+08,  ..., 1.7370e+08, 1.7313e+08,\n",
      "         1.7207e+08],\n",
      "        [2.4498e+08, 2.6377e+08, 2.6496e+08,  ..., 1.7454e+08, 1.7396e+08,\n",
      "         1.7290e+08],\n",
      "        ...,\n",
      "        [1.6115e+08, 1.7351e+08, 1.7429e+08,  ..., 1.1481e+08, 1.1443e+08,\n",
      "         1.1373e+08],\n",
      "        [1.6056e+08, 1.7288e+08, 1.7366e+08,  ..., 1.1439e+08, 1.1401e+08,\n",
      "         1.1332e+08],\n",
      "        [1.5957e+08, 1.7181e+08, 1.7258e+08,  ..., 1.1368e+08, 1.1331e+08,\n",
      "         1.1262e+08]])\n"
     ]
    }
   ],
   "source": [
    "score = torch.mm(Q, K.t())\n",
    "print(f\"Score: {score.shape}\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.]])\n",
      "Output: torch.Size([42, 1536])\n"
     ]
    }
   ],
   "source": [
    "d_k = Q.size(-1)  # Dimension of Key\n",
    "scaled_scores = score / torch.sqrt(torch.tensor(d_k, dtype=torch.float32)) # 현재 scripts/attention.py 의 ScaledDotProductAttention과 같은 역할\n",
    "attention_weights = torch.softmax(scaled_scores, dim=-1) # 나중에 전체 코드 통합할 때는 nn.object의 softmax를 사용해야 함함\n",
    "print(attention_weights)\n",
    "output = torch.mm(attention_weights, V)\n",
    "print(f\"Output: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scripts에 있는 베이스 코드들은 배치 사이즈가 고려된 클래스들로 이번 작업은 2D 작업이기 때문에 아래의 정의된 클래스는 배치 사이즈가 고려가 되지 않음.\n",
    "결합할 때 2D 임을 고려해야 함 ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention:\n",
    "    def __init__(self, embed_size: int, heads: int):\n",
    "        \"\"\"\n",
    "        Multi-Head Attention 초기화\n",
    "\n",
    "        Args:\n",
    "            embed_size (int): 임베딩 차원\n",
    "            heads (int): 어텐션 헤드 수\n",
    "        \"\"\"\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "\n",
    "        assert (\n",
    "            self.head_dim * heads == embed_size\n",
    "        ), \"임베딩 차원(embed_size)은 헤드 수(heads)로 나누어 떨어져야 합니다.\"\n",
    "\n",
    "        # Q, K, V 선형 변환을 위한 가중치 초기화\n",
    "        self.W_Q = torch.randn(embed_size, embed_size) * (self.head_dim ** -0.5)\n",
    "        self.W_K = torch.randn(embed_size, embed_size) * (self.head_dim ** -0.5)\n",
    "        self.W_V = torch.randn(embed_size, embed_size) * (self.head_dim ** -0.5)\n",
    "        self.W_O = torch.randn(embed_size, embed_size) * (self.head_dim ** -0.5)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        순전파 과정\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): 입력 텐서 [seq_length, embed_size]\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Multi-Head Attention 출력 [seq_length, embed_size]\n",
    "        \"\"\"\n",
    "        # Q, K, V 생성\n",
    "        Q = torch.matmul(x, self.W_Q)  # [seq_length, embed_size]\n",
    "        K = torch.matmul(x, self.W_K)  # [seq_length, embed_size]\n",
    "        V = torch.matmul(x, self.W_V)  # [seq_length, embed_size]\n",
    "\n",
    "        # 헤드 수에 맞게 분할\n",
    "        seq_length, embed_size = x.size()\n",
    "        Q = Q.view(seq_length, self.heads, self.head_dim).transpose(0, 1)  # [heads, seq_length, head_dim]\n",
    "        K = K.view(seq_length, self.heads, self.head_dim).transpose(0, 1)  # [heads, seq_length, head_dim]\n",
    "        V = V.view(seq_length, self.heads, self.head_dim).transpose(0, 1)  # [heads, seq_length, head_dim]\n",
    "\n",
    "        # Attention 스코어 계산\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))  # [heads, seq_length, seq_lengt]\n",
    "        # 현재 계산된 scores는 마스크가 없이 계산됨.. 마스크 추가해야 함..\n",
    "         \n",
    "        attention_weights = torch.softmax(scores, dim=-1)  # [heads, seq_length, seq_length]\n",
    "\n",
    "        # Attention 결과 계산\n",
    "        attention_out = torch.matmul(attention_weights, V)  # [heads, seq_length, head_dim]\n",
    "\n",
    "        # 헤드 결합\n",
    "        attention_out = attention_out.transpose(0, 1).contiguous().view(seq_length, embed_size)  # [seq_length, embed_size]\n",
    "\n",
    "        # 최종 선형 변환\n",
    "        out = torch.matmul(attention_out, self.W_O)  # [seq_length, embed_size]\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm:\n",
    "    def __init__(self, embed_size: int, eps: float = 1e-5):\n",
    "        \"\"\"\n",
    "        레이어 정규화 초기화\n",
    "\n",
    "        Args:\n",
    "            embed_size (int): 임베딩 차원\n",
    "            eps (float, optional): 안정성을 위한 작은 값. Defaults to 1e-5.\n",
    "        \"\"\"\n",
    "        self.gamma = torch.ones(embed_size, requires_grad=False)\n",
    "        self.beta = torch.zeros(embed_size, requires_grad=False)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        순전파 과정\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): 입력 텐서 [batch_size, seq_length, embed_size]\n",
    "\n",
    "        Returns:\n",
    "            Tensor: 정규화된 텐서\n",
    "        \"\"\"\n",
    "        self.mean = x.mean(dim=-1, keepdim=True)\n",
    "        self.std = x.std(dim=-1, keepdim=True)\n",
    "        self.normalized = (x - self.mean) / (self.std + self.eps)\n",
    "        return self.gamma * self.normalized + self.beta\n",
    "\n",
    "    def backward(self, grad_output: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        역전파 과정\n",
    "\n",
    "        Args:\n",
    "            grad_output (Tensor): 상위 레이어로부터 전달된 그래디언트\n",
    "\n",
    "        Returns:\n",
    "            Tensor: 하위 레이어로 전달할 그래디언트\n",
    "        \"\"\"\n",
    "        # 단순화를 위해 역전파는 gamma에 대한 기울기만 처리\n",
    "        return grad_output * self.gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock:\n",
    "    def __init__(self, embed_size: int, heads: int):\n",
    "        \"\"\"\n",
    "        Attention Block 초기화\n",
    "\n",
    "        Args:\n",
    "            embed_size (int): 임베딩 차원\n",
    "            heads (int): Multi-Head Attention의 헤드 수\n",
    "        \"\"\"\n",
    "        self.attention = MultiHeadAttention(embed_size, heads)\n",
    "        self.layer_norm = LayerNorm(embed_size)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        순전파 과정\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): 입력 텐서 [seq_length, embed_size]\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Attention Block 출력 [seq_length, embed_size]\n",
    "        \"\"\"\n",
    "        # Multi-Head Attention 수행\n",
    "        attention_out = self.attention.forward(x)\n",
    "\n",
    "        # Residual Connection + LayerNorm\n",
    "        out = self.layer_norm.forward(x + attention_out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttentionBlock Output Shape: torch.Size([42, 1536])\n"
     ]
    }
   ],
   "source": [
    "attention_block = AttentionBlock(embed_size=embedding_dim, heads=8) # MultiHeadAttention 수행..\n",
    "\n",
    "# Attention Block 순전파 수행\n",
    "attention_output = attention_block.forward(embedded)\n",
    "print(f\"AttentionBlock Output Shape: {attention_output.shape}\")  # Expected: [seq_length, embedding_dim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_output = torch.randn_like(attention_output)  # Same shape as attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42, 1536])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed_forward 클래스\n",
    "from nn_objects import Layer, Linear\n",
    "\n",
    "class FeedForward:\n",
    "    def __init__(self, embed_size: int, forward_expansion: int, activation):\n",
    "        \"\"\"\n",
    "        피드포워드 네트워크 초기화\n",
    "\n",
    "        Args:\n",
    "            embed_size (int): 임베딩 차원\n",
    "            forward_expansion (int): 피드포워드 네트워크의 확장 비율\n",
    "            activation (Activation): 활성화 함수\n",
    "        \"\"\"\n",
    "        self.fc1 = Layer(embed_size, embed_size * forward_expansion, activation) # 이번 예제는 relu 사용\n",
    "        self.fc2 = Layer(embed_size * forward_expansion, embed_size, Linear())  # Activation.Linear() -> Linear()로 수정\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        순전파 과정\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): 입력 텐서 [batch_size, seq_length, embed_size]\n",
    "\n",
    "        Returns:\n",
    "            Tensor: 피드포워드 네트워크 출력\n",
    "        \"\"\"\n",
    "        out = self.fc1.forward(x)\n",
    "        out = self.fc2.forward(out)\n",
    "        return out\n",
    "\n",
    "    def backward(self, grad_output: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        역전파 과정\n",
    "\n",
    "        Args:\n",
    "            grad_output (Tensor): 상위 레이어로부터 전달된 그래디언트\n",
    "\n",
    "        Returns:\n",
    "            Tensor: 하위 레이어로 전달할 그래디언트\n",
    "        \"\"\"\n",
    "        grad = self.fc2.backward(grad_output)\n",
    "        grad = self.fc1.backward(grad)\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention Block과 Feed Forward를 결합하여 완전한 Encoder Block을 구성\n",
    "class TransformerEncoderBlock:\n",
    "    def __init__(self, embed_size: int, heads: int, ff_dim: int, activation=torch.relu):\n",
    "        \"\"\"\n",
    "        Transformer Encoder Block 초기화\n",
    "\n",
    "        Args:\n",
    "            embed_size (int): 임베딩 차원\n",
    "            heads (int): Attention 헤드 수\n",
    "            ff_dim (int): Feed Forward 내부 차원\n",
    "        \"\"\"\n",
    "        self.attention = AttentionBlock(embed_size, heads)\n",
    "        self.feed_forward = FeedForward(embed_size, ff_dim, activation)\n",
    "        self.layer_norm_1 = LayerNorm(embed_size)\n",
    "        self.layer_norm_2 = LayerNorm(embed_size)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        순전파 과정\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): 입력 텐서 [seq_length, embed_size]\n",
    "\n",
    "        Returns:\n",
    "            Tensor: 출력 텐서 [seq_length, embed_size]\n",
    "        \"\"\"\n",
    "        # Attention Block + Residual Connection\n",
    "        attention_out = self.attention.forward(x)\n",
    "        x = self.layer_norm_1.forward(x + attention_out)\n",
    "\n",
    "        # Feed Forward + Residual Connection\n",
    "        feed_forward_out = self.feed_forward.forward(x)\n",
    "        out = self.layer_norm_2.forward(x + feed_forward_out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Output Shape: torch.Size([42, 1536])\n"
     ]
    }
   ],
   "source": [
    "ff_dim = 2048 # embedding_dim: 1536\n",
    "encoder_block = TransformerEncoderBlock(embed_size=embedding_dim, heads=8, ff_dim=ff_dim)\n",
    "\n",
    "# 순전파 수행\n",
    "encoder_output = encoder_block.forward(pos_encoded)\n",
    "print(f\"Encoder Output Shape: {encoder_output.shape}\")  # Expected: [seq_length, embedding_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection to vocabulary size\n",
    "class OutputProjection:\n",
    "    def __init__(self, embed_size: int, vocab_size: int):\n",
    "        \"\"\"\n",
    "        Output Projection Layer 초기화\n",
    "\n",
    "        Args:\n",
    "            embed_size (int): 임베딩 차원\n",
    "            vocab_size (int): 어휘 크기\n",
    "        \"\"\"\n",
    "        self.W = torch.randn(embed_size, vocab_size) * 0.01  # 가중치 초기화\n",
    "        self.b = torch.zeros(vocab_size)  # 바이어스 초기화\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        순전파 과정\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): 입력 텐서 [seq_length, embed_size]\n",
    "\n",
    "        Returns:\n",
    "            Tensor: 확률 분포를 위한 출력 [seq_length, vocab_size]\n",
    "        \"\"\"\n",
    "        return torch.matmul(x, self.W) + self.b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Projection Layer 초기화\n",
    "output_projection = OutputProjection(embed_size=embedding_dim, vocab_size=vocab_size)\n",
    "\n",
    "# encoder_output을 vocabulary 크기로 매핑\n",
    "logits = output_projection.forward(encoder_output)  # [seq_length, vocab_size]\n",
    "\n",
    "# Softmax를 통해 확률 계산\n",
    "probabilities = torch.softmax(logits, dim=-1)  # [seq_length, vocab_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Text: terstersters Ge Ge suggested Blackterstersizationization narr narr narr narr narr narr narr narr narr narr narrθθ leanedθθθ formＮmedmed sec secθnyny narr drawn Blackimesimes\n"
     ]
    }
   ],
   "source": [
    "# 가장 높은 확률의 토큰 선택\n",
    "predicted_token_ids = torch.argmax(probabilities, dim=-1)  # [seq_length]\n",
    "\n",
    "# 토큰 ID를 텍스트로 변환\n",
    "predicted_text = tokenizer.decode(predicted_token_ids.tolist())\n",
    "print(f\"Predicted Text: {predicted_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch220_cu118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
